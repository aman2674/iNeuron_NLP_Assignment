{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Assignment_4.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyP7bHiakBEeWr7zR+qi8DGl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# **NLP Assignment 4**"],"metadata":{"id":"pnERV7e6KrzQ"}},{"cell_type":"markdown","source":["---\n","---"],"metadata":{"id":"HABzV-p_KuX_"}},{"cell_type":"markdown","source":["## **Mention the steps that go into resolving any NLP issue.**"],"metadata":{"id":"-BYr1ST0Kvdd"}},{"cell_type":"markdown","source":["- Step 1: Gather your data. ...\n","- Step 2: Clean your data. ...\n","- Step 3: Find a good data representation. ...\n","- Step 4: Classification. ...\n","- Step 5: Inspection. ...\n","- Step 6: Accounting for vocabulary structure. ...\n","- Step 7: Leveraging semantics. ...\n","- Step 8: Leveraging syntax using end-to-end approaches."],"metadata":{"id":"0deLMYt3Kzh1"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"yodudOLKLQdC"}},{"cell_type":"markdown","source":["## **Mention how important word2vec is.**"],"metadata":{"id":"4IiXgYvoLRbL"}},{"cell_type":"markdown","source":["Usefulness of Word2vec is to group the vectors of similar words together in vectorspace. That is, it detects similarities mathematically. Word2vec creates vectors that are distributed numerical representations of word features, features such as the context of individual words. It does so without human intervention.\n","\n","Given enough data, usage and contexts, Word2vec can make highly accurate guesses about a word’s meaning based on past appearances. Those guesses can be used to establish a word’s association with other words (e.g. “man” is to “boy” what “woman” is to “girl”), or cluster documents and classify them by topic"],"metadata":{"id":"YEslIq3RLWXp"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"RMnXcWT9LwDG"}},{"cell_type":"markdown","source":["## **Explain the process of feature extraction in NLP.**"],"metadata":{"id":"0Cmqgx3cL0cj"}},{"cell_type":"markdown","source":["`Feature extraction` step means to extract and produce feature representations that are appropriate for the type of NLP task you are trying to accomplish and the type of model you are planning to use.\n","\n","Some of the most popular methods of feature extraction are :\n","\n","- Bag-of-Words\n","- TF-IDF\n","\n","`Bag of Words`\n","\n","The bag-of-words model is a simplifying representation used in NLP. In this model, a text is represented as the bag of its words, disregarding grammar and even word order but keeping multiplicity.\n","\n","There are 3 steps while creating a BoW model :\n","\n","1. The first step is text-preprocessing which involves:\n"," - converting the entire text into lower case characters.\n"," - removing all punctuations and unnecessary symbols.\n","\n","2. The second step is to create a vocabulary of all unique words from the corpus.\n","\n","3. In the third step, we create a matrix of features by assigning a separate column for each word, while each row corresponds to a review. This process is known as Text Vectorization\n","\n","`TF-IDF`\n","\n","TF-IDF stands for term frequency-inverse document frequency. It highlights a specific issue which might not be too frequent in our corpus but holds great importance. The TF–IFD value increases proportionally to the number of times a word appears in the document and decreases with the number of documents in the corpus that contain the word. It is composed of 2 sub-parts, which are :\n","\n","- Term Frequency (TF)\n","- Inverse Document Frequency (IDF)\n","\n","1. Term Frequency(TF) :\n","\n"," Term frequency specifies how frequently a term appears in the entire document.It can be thought of as the probability of finding a word within the document.\n","2. Inverse Document Frequency(IDF) :\n","\n"," The inverse document frequency is a measure of whether a term is rare or frequent across the documents in the entire corpus. It highlights those words which occur in very few documents across the corpus, or in simple language, the words that are rare have high IDF score. "],"metadata":{"id":"NfKxJSv3L2Pv"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"We_P9Py8NJvq"}},{"cell_type":"markdown","source":["## What is the distinction between precision and recall?"],"metadata":{"id":"ywMSRMusNK5e"}},{"cell_type":"markdown","source":["`Precision` = tp/(tp+fp )\n","\n","the precision for a class is the number of true positives divided by the total number of elements labeled as belonging to the positive class\n","\n","`Recall` = tp/(tp+fn)\n","\n","Recall in this context is defined as the number of true positives divided by the total number of elements that actually belong to the positive class\n","\n","\n","\n","Precision and recall counter each other, that is, increasing one of them reduces the other. Let’s look at the extreme cases: if you select almost everything, the precision is very low, while the recall is very high; if you select almost nothing, precision is very high, while the recall is very low. Therefore, the goal is to have some sort of a balance between the two. "],"metadata":{"id":"1MfkS4NpNO_I"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"wocc6Pq7NqpL"}},{"cell_type":"markdown","source":["# **Explain the concept of tokenization.**"],"metadata":{"id":"4a1vhwbiN5SY"}},{"cell_type":"markdown","source":["`Tokenization` is the act of breaking up a sequence of strings into pieces such as words, keywords, phrases, symbols and other elements called tokens. Tokens can be individual words, phrases or even whole sentences. In the process of tokenization, some characters like punctuation marks are discarded. The tokens become the input for another process like parsing and text mining.\n","\n","Tokenization relies mostly on simple heuristics in order to separate tokens by following a few steps:\n","\n","- Tokens or words are separated by whitespace, punctuation marks or line breaks\n","- White space or punctuation marks may or may not be included depending on the need\n","- All characters within contiguous strings are part of the token. Tokens can be made up of all alpha characters, alphanumeric characters or numeric characters only"],"metadata":{"id":"hZYZd9vKN7VQ"}},{"cell_type":"markdown","source":["---"],"metadata":{"id":"PZNNwjK9OXq2"}},{"cell_type":"markdown","source":["## **Mention the distinction between formal and informal language.**"],"metadata":{"id":"0MKQEttmO5gV"}},{"cell_type":"markdown","source":["`Formal language` respects the “form”, that is the rules of language, whether grammar rules or codes of vocabulary, depending on whom you are speaking to.\n","\n","`Informal language` is the language you use with your children, family, co-workers or friends, without bothering too much about proper grammar, appropriate vocabulary or received pronunciation. Colloquial language, baby-talk and slang are inform\n","\n","Formal and informal language each serve a different purpose. The choice of words, the tone and the way that each word is strung together will vary depending on the situation and the level of formality. Formal language is, for all intents and purposes, far less personal than informal writing.\n","\n"],"metadata":{"id":"jGj7INrjOsm9"}},{"cell_type":"markdown","source":["---\n","---"],"metadata":{"id":"SuuyUiNUPBdz"}}]}